# HUM2019
This is a natural language processing algorithm that takes in the wikipedia description of a novel and writes a fanfiction of it. 
It has not been what is refered to as "tuned" in NLP, meaning it needs more data for GPT-2 to work with to function, howwever,
HacKUMass is 36 hours long, so I didn't have to time to train it longer than it has been. It uses pytorch-based transformers to
implement GPT-2, which were provided courtesy of AWS.
